<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="stages of memory  these stages occur as a sequence they are interdependent on each other  encoding  process of converting information into usable form that can be stored  automatic encoding involves encoding information about location in space and time and frequency of experience effortful encoding involves attending to information, labelling then associating it with other things in memory   requires selective attention to the material being encoded visual encoding is the processing of images, acoustic encoding is the processing of sound (particularly of words), semantic encoding is the processing of meaning (of words)  storage  retention of information in memory over time  retrieval  process of locating and recovering stored info from memory so that we are consciously aware of it not a random process, involves various elements of cues, moods, schema, and is subject to errors  multi-store model of memory (atkinson and shiffrin)  proposed in 1968 human memory is said to consist of three separate components  sensory short-term long-term   these components are characterised by a specific duration and capacity certain conditions have to be met in order to make info move to the next memory-store !"><title>models of memory</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://axeolotl69.github.io/stalactite/icon.png><link href=https://axeolotl69.github.io/stalactite/styles.547fb332ce56cdc523146ba5ede80d7f.min.css rel=stylesheet><link href=https://axeolotl69.github.io/stalactite/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://axeolotl69.github.io/stalactite/js/darkmode.6907787bc4f89e093466b511dafacc34.min.js></script>
<script src=https://axeolotl69.github.io/stalactite/js/util.6f22941e242efae60fd84e7c32e874fa.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script async src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script async src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script async src=https://axeolotl69.github.io/stalactite/js/popover.f03552ccb84d99ca615d1cfb9abde59e.min.js></script>
<script defer src=https://axeolotl69.github.io/stalactite/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://axeolotl69.github.io/stalactite/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://axeolotl69.github.io/stalactite/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://axeolotl69.github.io/stalactite",fetchData=Promise.all([fetch("https://axeolotl69.github.io/stalactite/indices/linkIndex.4b10e258396e52159325ab811062d360.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://axeolotl69.github.io/stalactite/indices/contentIndex.4546ec1f4e7485c5c683669f2040ff06.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://axeolotl69.github.io/stalactite",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://axeolotl69.github.io/stalactite",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'‚Äô':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/axeolotl69.github.io\/stalactite\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://axeolotl69.github.io/stalactite/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://axeolotl69.github.io/stalactite>ü™êstalactite</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>models of memory</h1><p class=meta>Last updated
May 31, 2023
<a href=https://github.com/axeolotl69/stalactite/tree/hugo/content/notes/psych/cognitive%20approach/models%20of%20memory.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#stages-of-memory>stages of memory</a><ol><li><a href=#encoding>encoding</a></li><li><a href=#storage>storage</a></li><li><a href=#retrieval>retrieval</a></li></ol></li></ol><ol><li><ol><li><a href=#sensory-memory>sensory memory</a></li><li><a href=#short-term-memory>short term memory</a></li><li><a href=#long-term-memory>long term memory</a></li></ol></li><li><a href=#serial-position-effect>serial position effect</a></li></ol><ol><li><ol><li><a href=#central-executive>central executive</a></li><li><a href=#visuospatial-sketchpad>visuospatial sketchpad</a></li><li><a href=#phonological-loop>phonological loop</a></li><li><a href=#episodic-buffer>episodic buffer</a></li></ol></li></ol></nav></details></aside><a href=#stages-of-memory><h2 id=stages-of-memory><span class=hanchor arialabel=Anchor># </span>stages of memory</h2></a><ul><li>these stages occur as a sequence</li><li>they are interdependent on each other</li></ul><a href=#encoding><h3 id=encoding><span class=hanchor arialabel=Anchor># </span>encoding</h3></a><ul><li>process of converting information into usable form that can be stored<ul><li><strong>automatic encoding</strong> involves encoding information about location in space and time and frequency of experience</li><li><strong>effortful encoding</strong> involves attending to information, labelling then associating it with other things in memory</li></ul></li><li>requires selective attention to the material being encoded</li><li><strong>visual</strong> encoding is the processing of images, <strong>acoustic</strong> encoding is the processing of sound (particularly of words), <strong>semantic</strong> encoding is the processing of meaning (of words)</li></ul><a href=#storage><h3 id=storage><span class=hanchor arialabel=Anchor># </span>storage</h3></a><ul><li>retention of information in memory over time</li></ul><a href=#retrieval><h3 id=retrieval><span class=hanchor arialabel=Anchor># </span>retrieval</h3></a><ul><li>process of locating and recovering stored info from memory so that we are consciously aware of it</li><li><u>not a random process</u>, involves various elements of cues, moods, schema, and is subject to errors</li></ul><a href=#multi-store-model-of-memory-atkinson-and-shiffrin><h1 id=multi-store-model-of-memory-atkinson-and-shiffrin><span class=hanchor arialabel=Anchor># </span>multi-store model of memory (atkinson and shiffrin)</h1></a><ul><li>proposed in 1968</li><li>human memory is said to consist of three separate components<ul><li>sensory</li><li>short-term</li><li>long-term</li></ul></li><li>these components are characterised by a specific duration and capacity</li><li>certain conditions have to be met in order to make info move to the next memory-store
<a class="internal-link broken">Pasted image 20230523135507.png</a></li></ul><a href=#sensory-memory><h3 id=sensory-memory><span class=hanchor arialabel=Anchor># </span>sensory memory</h3></a><ul><li>does not process information</li><li>capacity: <u>large</u>, duration: <u>short</u></li><li>condition that has to be met for info to transfer to STM is <strong>attention</strong></li></ul><a href=#sensory-registers><h4 id=sensory-registers><span class=hanchor arialabel=Anchor># </span>sensory registers</h4></a><ul><li>sensory info is thought to be stored in seaparate sensory registers</li><li>thought that each of the five senses has a separate register</li></ul><a href=#iconic-memory><h5 id=iconic-memory><span class=hanchor arialabel=Anchor># </span>iconic memory</h5></a><ul><li>visual sensory memory</li><li>stores visual images in original sensory form for 1/3 second</li></ul><a href=#echoic-memory><h5 id=echoic-memory><span class=hanchor arialabel=Anchor># </span>echoic memory</h5></a><ul><li>auditory sensory memory</li><li>stores sounds in original sensory form for about 3-4 seconds</li><li>important in speech comprehension</li></ul><a href=#short-term-memory><h3 id=short-term-memory><span class=hanchor arialabel=Anchor># </span>short term memory</h3></a><ul><li>info is an encoded form of raw info (not exact)</li><li>holds info consciously aware of</li><li>capacity: <u>7 +/- 2 (5-9 things)</u>, duration: <u>no longer than 30 secs</u></li><li>if left unattended the trace fades away</li></ul><a href=#long-term-memory><h3 id=long-term-memory><span class=hanchor arialabel=Anchor># </span>long term memory</h3></a><ul><li>capacity: <u>unlimited</u>, duration: <u>unlimited</u></li><li>two main types of LTM:<ul><li><strong>explicit</strong> (episodic and semantic)</li><li><strong>implicit</strong> (procedural memory and classically conditioned memory)</li></ul></li></ul><a href=#serial-position-effect><h2 id=serial-position-effect><span class=hanchor arialabel=Anchor># </span>serial position effect</h2></a><ul><li>recall accuracy varies as a function of an item&rsquo;s position within a study list</li><li><u>primacy effect</u>: earlier items recalled more frequently than middle items<ul><li>initial items presented are most effectively stored in LTM because of greater amount of attention/processing</li></ul></li><li><u>recency effect</u>: things at the end of a list are recalled first<ul><li>suggests these items are still present in working/STM</li></ul></li></ul><a href=#working-model-of-memory><h1 id=working-model-of-memory><span class=hanchor arialabel=Anchor># </span>working model of memory</h1></a><ul><li>development of multi-store model of memory
<a class="internal-link broken">Pasted image 20230530205712.png</a></li><li>baddely and hitch (1974) developed the working memory model ^^</li><li>working memory consists of a central executive that coordinates two subsystems:</li></ul><a href=#central-executive><h3 id=central-executive><span class=hanchor arialabel=Anchor># </span>central executive</h3></a><ul><li>a system that allocates resources between visuospatial sketchpad and phonological loop</li><li>the <strong>manager</strong> for the other two systems</li><li>directs attention towards tasks</li></ul><a href=#visuospatial-sketchpad><h3 id=visuospatial-sketchpad><span class=hanchor arialabel=Anchor># </span>visuospatial sketchpad</h3></a><ul><li><u>limited capacity</u> (like the MSM&rsquo;s STM store)</li><li>holds visual and spatial info</li><li>visual cache = what things look like, stores info about form and colour</li><li>inner scribe = processes spatial and movement info</li></ul><a href=#phonological-loop><h3 id=phonological-loop><span class=hanchor arialabel=Anchor># </span>phonological loop</h3></a><ul><li><u>limited capacity</u></li><li>deals with auditory info and language (written + spoken)</li><li>further divided into the <strong>phonological</strong> store (holds word heard) and the <strong>articulatory</strong> process (holds words heard/seen silently repeated, like an inner voice)</li></ul><a href=#inner-ear><h4 id=inner-ear><span class=hanchor arialabel=Anchor># </span>inner ear</h4></a><p>holds sound in a passive manner; eg someone&rsquo;s speech</p><a href=#inner-voice><h4 id=inner-voice><span class=hanchor arialabel=Anchor># </span>inner voice</h4></a><ul><li>turns visual stimuli into sounds; eg shown a list of written words, pronounce these words in mind</li><li>allows rehearsal of info - by repeating info, increases duration of working memory + increases chance of transferring to long term memory</li></ul><a href=#episodic-buffer><h3 id=episodic-buffer><span class=hanchor arialabel=Anchor># </span>episodic buffer</h3></a><ul><li>(added later) component that integrates info from the other components and links to long term memory structures</li><li>time sequencing</li><li>eg memory of a story, event, movie scene</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/stalactite/notes/psych/psychology/ data-ctx="working model of memory" data-src=/notes/psych/psychology class=internal-link>psychology</a></li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://axeolotl69.github.io/stalactite/js/graph.6421b50adba269f8b1f5b3e0dc679564.js></script></div></div><div id=contact_buttons><footer><p>Made by will smith using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2023</p><ul><li><a href=https://axeolotl69.github.io/stalactite>Home</a></li></ul></footer></div></div></body></html>